# Lecture 8 | Depth Estimation

!!! warning "注意"
    本文尚未完全整理好！

---

稀疏的点云 + 图像 ----> 稠密结果

## Depth estimation

深度在深度图上的表现十分稠密，每一个像素都具有深度属性。

> Active depth sensing 主动深度探测 （非视觉方法）
> 
> - LiDAR
> - Structured light
> - Active stereo

Passive depth sensing 被动深度探测

- Stereo
- Multi-view stereo
- Monocular

### Stereo matching

- Stereo vision
    - “视差”
    - 原理是三角测量
    - 继续使用之前的方法，很难有效计算所有的像素点的对应关系，而高效实现这一点，就是 stereo matching，立体匹配
    - 回顾 **[对极几何](./Lec07.md#对极几何)**
    - 在本节，我们需要重点关注对极线
    - 已知 $X_L$，$X_R$ 的位置一定在 R 平面的对极线上，其线方程正是 $X_L^T F X_R$。而这个结论可以大大降低查找 pixel 的复杂度。我们只需要在一条线上搜索比较匹配即可。
    - 然而如果对于每个点都需要计算对极线，那也非常糟糕，所以我们希望能有一些特殊情况——比如，（……）相机如果只有水平移动和旋转，那么对极线都会是水平的，Simplest Case 会让一切相关计算和步骤变简单
        - disparity 视差 = x2 - x1（对于各自的坐标系）
        - 通过视差可以计算深度（相似三角形）
    - 而对于并非 simplest case 的一般情况，我们可以考虑把当前情况转化为 simplest case——使用 stereo image rectification，细节不展开
- 基础的 Stereo matching 算法
    - 计算相似度，查找相似度最小的地方
    - 常见的 Matching Scores
        - SSD(Sum of Squared Differences)
        - SAD(Sum of Absolute Differences)
        - ZNCC(Zero-mean Normalized Cross Correlation) （协方差？，互相关？）对图像整体亮度差异不大敏感
    - 还有一个问题是选取的窗口大小，有一个精确度和平滑度的 trade-off
    - 于是有一个改进就是考虑空间上的连续性，方法就是转化为优化问题，在目标函数同时考虑匹配度和在临域的平滑度（视差剧烈程度）
        - 而求解这个最优化的问题，在上面提到的「临域」只涉及像素点左侧和右侧，即线性约束时，可以使用 DP 来做，但是在非线性约束下，这个问题变成 NP-hard 问题，只能求近似解，可以使用图割来做
    - Pipeline
        - ...
    - 常见误差出现的地方（大作业提示）
        - ...
    - Baseline 对计算的影响，：
        - 太大（景象变化更大，搜索更难）
        - 太小（可以通过相交得到的四边形长度体现出来）
    - 对于纹理不明显的内容，如果想要去重建，有一种办法是手动增加纹理，比如手动打变化明显的结构光
        - 而在结构光下，我们可以去掉一个相机，因为在投影仪位置的相机，在特定参数下拍到的景象和射出去的内容可能十分相似（貌似默认漫反射时能量不消损，但是不考虑光斑亮暗，单看结构来说应该是这样的）
- multi-view stereo  MVS
    - 好处是约束更强、选择更多、构建更完整
    - 具体做法是
        - 枚举一个视角里对极线上的深度，然后用在其他视角里的重投影匹配度做评估，找到效果最好的深度
        - 其中一个问题是如何高效的计算所有的误差
        - 可以使用 Plane-Sweep
            - 对于每一个其他视角，构造一个关于 x-y-z 的三维表，能够查询对于参考图片`[x][y]`处的像素，如果处于深度`[z]`时的情况
            - 利用两次投影，先在“A”字里相似到远处，然后再斜着投影到每个视角里
            - 每一层层扫过去
            - ![](92.gif)
                - 在上图数组里找每一个`[x][y]`里表现最好的`[z]`作为那个像素的深度。
            - 然而这个做法还是不太高效，一个更高效的做法，是 PatchMatch。
                - 随即初始化，总有几个是接近最优解的
                - 对于这些比较优的解，它附近的像素答案在这个答案的附近寻找（传播），然后再在小范围内进一步优化（搜索）

## 3D reconstruction

具体来说，3D 重建包括这么三个步骤：

1. 深度计算
2. 深度 -> 3D网格表面
3. 纹理填充

### 3D representations

补充图片

- 点云 point cloud
- 体素（3d像素）occupancy
- signed distance function (SDF)
    - 大小距离表面的距离，内部为负，外部为正
    - Truncated Signed Distance Function 截断SDF，即仍和大于 1 都记为 1，小于 -1 的记为 -1
- 网格 mesh（比较常用）

### 3D surface reconstruction

1. 深度 -> 体素表示
2. 体素表示 -> 三维网格

#### 深度 -> 体素表示

常用方法：

##### Depth Fusion （depth maps to TSDF）

【对于图中】：

- 可以计算每一个体素到相机中心的距离 $d_p$
- 根据小孔成像规则，可以得到与当前体素所对应的像素，记对应的像素的深度为 $D_k(u)$
- 则该体素的 TSDF 值截断前为 $D_k(u) - d_p$
- 在多图情况下，每一张图的结果做加权计算

!!! tip "思路"
    之前也有类似的内容。一个总结性的想法是，当你需要把「分辨率」低的东西投影到「分辨率」高到地方去时，应当枚举「分辨率」高的那一侧的单元，然后利用「分辨率」低的这一侧去计算，而不是从低到高。

##### Poisson reconstruction （depth maps to occupancy volume）

柏松重建

- 深度图 -> 带法向量的点云
    - Oriented points 那里的箭头是表面法向量（深度的梯度）
- 用优化的方式求解 indicator function （大概就是最终结果的那个物体的表面发向量函数）
    - 这里有一个点就是，体素的曲面是闭合的，所以会有内外之分，内部实心外部空心，所以 indicator function 就是想同时表达 表面 和 内外 两件事。

#### 体素表示 -> 三维网格

常用方法：

Marching cubes

- 以 2D 为例，如果一个「边」的两边，黑白不一致（黑表示外部，白表示内部），则说明这里存在一个边界，于是标一个点，然后将所有的这样的点按照特定顺序连接起来，就得到的了边界。
- 具体标在边界的哪个位置，如果是 SDF 的话可以计算知道，否则可能只能在中间了
- 但是需要注意一个格子如果有多个点的时候怎么连的问题，有一个表可以查，撑死也就 2^4=16 种情况

- 在 3D 情况下，就是在立方体里连接三个点形成三角面，然后也有一个表可以查，撑死也就 2^8=256 种情况。

![](93.gif)

### Texture mapping

展开 get 纹理图（二维坐标能够对应一个网格面） using 参数化


